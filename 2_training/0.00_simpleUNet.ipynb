{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1c63156-d3d6-4855-84a9-bc7e1c4eb6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import bioMass.dataViz as dv\n",
    "from bioMass.dataloader import SentinelDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a17c85-b523-424a-8899-873cdab7c37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training device: cuda\n",
      "loader_device: cpu\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/docs/master/notes/mps.html\n",
    "\n",
    "if torch.backends.mps.is_available(): # Mac M1/M2\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "loader_device = torch.device('cpu')  # found that using cpu for data loading was faster than gpu (for my device)\n",
    "print(f'training device: {device}')\n",
    "print(f'loader_device: {loader_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5af6a0-0477-4369-a61d-5a56761f5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_tiles = '/home/ubuntu/Thesis/backup_data/bioMass_data/train_PCA_warm/'\n",
    "dir_target = '/home/ubuntu/Thesis/backup_data/bioMass_data/train_agbm/'\n",
    "dir_saved_models = '/home/ubuntu/Thesis/backup_data/bioMass_data/trained_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4296e29a-af94-4da1-8588-ca1ff2623d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chips = 100 # number of chips to use from training set, None = Use All  \n",
    "\n",
    "# A custom dataloader for Sentinel data \n",
    "dataset = SentinelDataset(dir_tiles=dir_tiles, dir_target=dir_target,\n",
    "                          max_chips=max_chips, transform=None,\n",
    "                          device=loader_device\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a564ab-8ef3-4af6-a711-4e0d5d33db18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N training samples: 70\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_frac = 0.7\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_frac, 1-train_frac-0.1, 0.1])\n",
    "print(f'N training samples: {len(train_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c579fc83-89f1-4af6-a886-20dac66f5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # Note: training speed is sensitive to memory usage\n",
    "                 # set this as high as you can without significantly slowing down training time \n",
    "num_workers = 1\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=True\n",
    "                             )\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=num_workers,\n",
    "                            pin_memory=True\n",
    "                           )\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=num_workers,\n",
    "                            pin_memory=True\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2575bb09-daee-47df-bfd3-1554303fca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_dataloader:\n",
    "    sample\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aacbf3d2-bbad-41a9-88c7-c6cb3c28fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioMass.model import S2_Unet_pytorch, S2_Unet_pytorch0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d0b539d-28ae-48c2-9d8a-d6d3de541f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 11, 256, 256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['image_s2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cfc8bd7-ecc1-47ec-9607-7b838ad306ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 256, 256])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = S2_Unet_pytorch(64, 11, 0.5)\n",
    "\n",
    "out = model(sample['image_s2']).shape\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc806940-5999-451d-88fa-ec1f04626a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# input channels: 11\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "in_channels = train_dataset[0]['image_s2'].shape[0]\n",
    "print(f'# input channels: {in_channels}')\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet50\",\n",
    "    encoder_weights=None, # 'imagenet' weights don't seem to help so start clean \n",
    "    in_channels=in_channels,                 \n",
    "    classes=1,                     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bad8b8d1-12ae-454b-bbd7-3ce78a577b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 256, 256])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample['image_s2']).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
